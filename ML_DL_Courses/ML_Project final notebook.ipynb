{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exploratory data analysis was performed as entries with missing data were removed, the data was already normalized and removing outliers would not be ideal as the normal varience in the population is uknown for all 62000 transcripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added relative path, place path where data is in this line.\n",
    "data = pd.read_csv(\"C:/Users/migue/OneDrive/Desktop/ML Project/Counts/Individual Files/Extracted/Invidual/ML_project_Clinical only.csv\")\n",
    "print(data)\n",
    "#Need to work on this.\n",
    "x_frame = data.iloc[: , :-1]\n",
    "#x_frame = x_frame.to_numpy()\n",
    "\n",
    "y_frame = data.iloc[:,-1:]\n",
    "\n",
    "\n",
    "print(x_frame)\n",
    "print(y_frame)\n",
    "\n",
    "print(x_frame.shape)\n",
    "\n",
    "print(y_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set varibles for data scaling and  stratified Kfold for the hw examples.\n",
    "# Will need to do boostrapping not stratified kfold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "le = preprocessing.LabelEncoder()\n",
    "oe = OrdinalEncoder()\n",
    "x_frame = oe.fit_transform(x_frame)\n",
    "print(y_frame)\n",
    "y_frame = le.fit_transform(y_frame)\n",
    "print(y_frame)\n",
    "#(categories = ['Age at Index','Age of Diagnosis in Days','Days from Birth','Days to Last Follow UP','Gender','Sample Type','Treament Or Therapy','Treatment Type','Vital Status'])\n",
    "cv_outer = StratifiedKFold(n_splits=6, shuffle=True, random_state=1)\n",
    "cv_inner = StratifiedKFold(n_splits=6, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses CV inner to determine best parameters for xgb using the RandomizedSearchCV parameter optimization. \n",
    "model_xgb = xgb.XGBClassifier(random_state=1,objective='multi:softmax',eval_metric='logloss',use_label_encoder=False,num_class =8)\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('pca', PCA()), \n",
    "    ('model_xgb', model_xgb,)\n",
    "])\n",
    "\n",
    "xgb_param= {\n",
    "    'pca__n_components': [0.60,0.70,0.80,0.90],\n",
    "    'model_xgb__max_depth': [2, 3, 5,7,9],\n",
    "    'model_xgb__n_estimators': [10, 100, 500],\n",
    "    'model_xgb__average':['none','micro','macro','weighted']}\n",
    "xgb_random = RandomizedSearchCV(xgb_pipeline, xgb_param, cv=cv_inner, scoring='accuracy')\n",
    "print(xgb_random)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code below is an example for the hw assignment for how to perform nested k fold on the stratified k fold splits previously.\n",
    "#Sets variables for the following for loop in the code below. \n",
    "import warnings \n",
    "#Silences warnings. \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rf_outer_results = list()\n",
    "rf_best_f1_score=float('-inf')\n",
    "rf_best_parameters={}\n",
    "\n",
    "xgb_outer_results = list()\n",
    "xgb_best_f1_score= float('-inf')\n",
    "xgb_best_parameters={}\n",
    "\n",
    "#for loop that runs 1 times that uses the optimized parameters from above to train the models using a new outer split of the data. \n",
    "iter_num=1\n",
    "for train_ix, test_ix in cv_outer.split(x_frame,y_frame):\n",
    "    print('Iteration',iter_num)\n",
    "    iter_num +=1\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_frame, y_frame, random_state = 1)\n",
    "    print(type(X_test))\n",
    "    #X_train, X_test = x_frame[train_ix, :], x_frame[test_ix, :]\n",
    "    #y_train, y_test = y_frame[train_ix], y_frame[test_ix]\n",
    "\n",
    "    #XGBoost\n",
    "    result = xgb_random.fit(X_train, y_train)\n",
    "    best_model = result.best_estimator_\n",
    "    yhat = best_model.predict(X_test)\n",
    "    f1score=f1_score(y_test,yhat,average ='weighted')\n",
    "    if f1score >= xgb_best_f1_score:       \n",
    "        xgb_best_f1_score=f1score\n",
    "        xgb_best_parameters=result.best_params_\n",
    "    xgb_outer_results.append(f1score)\n",
    "    print('XGB inner test: est=%.3f, cfg=%s' % (result.best_score_, result.best_params_))\n",
    "    print()\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "\n",
    "xgb_mean=np.mean(xgb_outer_results)\n",
    "\n",
    "print('XGB outer test: f1-score mean: %.3f (std: %.3f)' % (xgb_mean, np.std(xgb_outer_results)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the highest mean between the trained models, it then returns the best performing model based on that. \n",
    "defaulttParm=model_xgb.get_xgb_params()\n",
    "pca=PCA(xgb_best_parameters['pca__n_components'])\n",
    "for k in xgb_best_parameters.keys():\n",
    "    if 'model_xgb' in k:\n",
    "        parm=k.split('__')[1]\n",
    "        defaulttParm[parm]=xgb_best_parameters[k]\n",
    "defaulttParm['use_label_encoder']=False\n",
    "myFinalModel=xgb.XGBClassifier(**defaulttParm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "x_pca=pca.fit_transform(x_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the cross validation scores.\n",
    "print(cross_val_score(myFinalModel,x_pca, y_frame,cv=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(myFinalModel,x_frame, y_frame,cv=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines the f-score of the model using a new tenth split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_frame, y_frame, test_size=0.1, random_state=1)\n",
    "myFinalModel.fit(X_train,y_train)\n",
    "yhat=myFinalModel.predict(X_test)\n",
    "f1score=f1_score(yhat,y_test, average ='weighted')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "print(type(explainer))\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X_test[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "shap.force_plot(explainer.expected_value, shap_values[1], X_test[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 0.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[0],X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 1.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[1],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the learning curve function from the yellowbrick library to identify if the model could benefit from more training samples. \n",
    "from yellowbrick.model_selection import learning_curve\n",
    "#prints the learning curve plot. \n",
    "print(learning_curve(myFinalModel,X_test, y_test,cv=10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "# create dataset with n_samples. \n",
    "X, y = make_classification(n_samples=100000, random_state=1)\n",
    "# split into train test sets 80 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# define lists to collect accuracy scores. \n",
    "train_scores, test_scores = list(), list()\n",
    "# define the tree depths to evaluate\n",
    "values = [i for i in range(1, 21)]\n",
    "#for loop that takes split above and plots train vs test to determine fit.\n",
    "for i in values:\n",
    "    myFinalModel.fit(X_train, y_train)\n",
    "    # evaluate on the train dataset\n",
    "    train_yhat = myFinalModel.predict(X_train)\n",
    "    #determines accuracy score of training data set model.\n",
    "    train_acc = accuracy_score(y_train, train_yhat)\n",
    "    #appends train accuracy score to list. \n",
    "    train_scores.append(train_acc)\n",
    "    # evaluate on the test dataset\n",
    "    test_yhat = myFinalModel.predict(X_test)\n",
    "    #determines accuracy score of test data set model \n",
    "    test_acc = accuracy_score(y_test, test_yhat)\n",
    "    #appends the test accuracy score to list. \n",
    "    test_scores.append(test_acc)\n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n",
    "# plot of train and test scores \n",
    "pyplot.plot(values, train_scores, '-o', label='Train')\n",
    "pyplot.plot(values, test_scores, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical plus transport transcripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added relative path, place path where data is in this line.\n",
    "data = pd.read_csv(\"C:/Users/migue/OneDrive/Desktop/ML Project/Counts/Individual Files/Extracted/Invidual/transposed_transport_genes.csv\")\n",
    "print(data)\n",
    "#Need to work on this.\n",
    "x_frame = data.iloc[: , :-1]\n",
    "#x_frame = x_frame.to_numpy()\n",
    "\n",
    "y_frame = data.iloc[:,-1:]\n",
    "\n",
    "\n",
    "print(x_frame)\n",
    "print(y_frame)\n",
    "\n",
    "print(x_frame.shape)\n",
    "\n",
    "print(y_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set varibles for data scaling and  stratified Kfold for the hw examples.\n",
    "# Will need to do boostrapping not stratified kfold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "le = preprocessing.LabelEncoder()\n",
    "oe = OrdinalEncoder()\n",
    "x_frame = oe.fit_transform(x_frame)\n",
    "print(y_frame)\n",
    "y_frame = le.fit_transform(y_frame)\n",
    "print(y_frame)\n",
    "#(categories = ['Age at Index','Age of Diagnosis in Days','Days from Birth','Days to Last Follow UP','Gender','Sample Type','Treament Or Therapy','Treatment Type','Vital Status'])\n",
    "cv_outer = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses CV inner to determine best parameters for xgb using the RandomizedSearchCV parameter optimization. \n",
    "model_xgb = xgb.XGBClassifier(random_state=1,objective='multi:softmax',eval_metric='mlogloss',use_label_encoder=False,num_class =8)\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('pca', PCA()), \n",
    "    ('model_xgb', model_xgb,)\n",
    "])\n",
    "\n",
    "xgb_param= {\n",
    "    'pca__n_components': [0.60,0.70,0.80,0.90],\n",
    "    'model_xgb__max_depth': [2, 3, 5,7,9],\n",
    "    'model_xgb__n_estimators': [10, 100, 500],\n",
    "    'model_xgb__average':['none','micro','macro','weighted']}\n",
    "xgb_random = RandomizedSearchCV(xgb_pipeline, xgb_param, cv=cv_inner, scoring='accuracy')\n",
    "print(xgb_random)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code below is an example for the hw assignment for how to perform nested k fold on the stratified k fold splits previously.\n",
    "#Sets variables for the following for loop in the code below. \n",
    "import warnings \n",
    "#Silences warnings. \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rf_outer_results = list()\n",
    "rf_best_f1_score=float('-inf')\n",
    "rf_best_parameters={}\n",
    "\n",
    "xgb_outer_results = list()\n",
    "xgb_best_f1_score= float('-inf')\n",
    "xgb_best_parameters={}\n",
    "\n",
    "#for loop that runs 1 times that uses the optimized parameters from above to train the models using a new outer split of the data. \n",
    "iter_num=1\n",
    "for train_ix, test_ix in cv_outer.split(x_frame,y_frame):\n",
    "    print('Iteration',iter_num)\n",
    "    iter_num +=1\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_frame, y_frame, train_size =0.8,test_size =0.2, random_state = 1)\n",
    "    #X_train, X_test = x_frame[train_ix, :], x_frame[test_ix, :]\n",
    "    #y_train, y_test = y_frame[train_ix], y_frame[test_ix]\n",
    "\n",
    "    #XGBoost\n",
    "    result = xgb_random.fit(X_train, y_train)\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    yhat = best_model.predict(X_test)\n",
    "    f1score=f1_score(y_test,yhat,average ='weighted')\n",
    "    if f1score >= xgb_best_f1_score:       \n",
    "        xgb_best_f1_score=f1score\n",
    "        xgb_best_parameters=result.best_params_\n",
    "    xgb_outer_results.append(f1score)\n",
    "    print('XGB inner test: est=%.3f, cfg=%s' % (result.best_score_, result.best_params_))\n",
    "    print()\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "\n",
    "xgb_mean=np.mean(xgb_outer_results)\n",
    "\n",
    "print('XGB outer test: f1-score mean: %.3f (std: %.3f)' % (xgb_mean, np.std(xgb_outer_results)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the highest mean between the trained models, it then returns the best performing model based on that. \n",
    "defaulttParm=model_xgb.get_xgb_params()\n",
    "pca=PCA(xgb_best_parameters['pca__n_components'])\n",
    "for k in xgb_best_parameters.keys():\n",
    "    if 'model_xgb' in k:\n",
    "        parm=k.split('__')[1]\n",
    "        defaulttParm[parm]=xgb_best_parameters[k]\n",
    "defaulttParm['use_label_encoder']=False\n",
    "myFinalModel=xgb.XGBClassifier(**defaulttParm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "x_pca=pca.fit_transform(x_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(myFinalModel,x_frame, y_frame,cv=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines the f-score of the model using a new tenth split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_frame, y_frame, test_size=0.1, random_state=1)\n",
    "myFinalModel.fit(X_train,y_train)\n",
    "yhat=myFinalModel.predict(X_test[0:,])\n",
    "print(yhat)\n",
    "f1score=f1_score(yhat,y_test, average ='weighted')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[1], X_test[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "shap.force_plot(explainer.expected_value, shap_values[10], X_test[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 0.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[0],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 1.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[1],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)\n",
    "shap_object = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values[1],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the learning curve function from the yellowbrick library to identify if the model could benefit from more training samples. \n",
    "\n",
    "from yellowbrick.model_selection import learning_curve\n",
    "\n",
    "print(learning_curve(myFinalModel,x_frame, y_frame,cv=10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "# create dataset with n_samples. \n",
    "X, y = make_classification(n_samples=100000, random_state=1)\n",
    "# split into train test sets 80 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# define lists to collect accuracy scores. \n",
    "train_scores, test_scores = list(), list()\n",
    "# define the tree depths to evaluate\n",
    "values = [i for i in range(1, 21)]\n",
    "#for loop that takes split above and plots train vs test to determine fit.\n",
    "for i in values:\n",
    "    myFinalModel.fit(X_train, y_train)\n",
    "    # evaluate on the train dataset\n",
    "    train_yhat = myFinalModel.predict(X_train)\n",
    "    #determines accuracy score of training data set model.\n",
    "    train_acc = accuracy_score(y_train, train_yhat)\n",
    "    #appends train accuracy score to list. \n",
    "    train_scores.append(train_acc)\n",
    "    # evaluate on the test dataset\n",
    "    test_yhat = myFinalModel.predict(X_test)\n",
    "    #determines accuracy score of test data set model \n",
    "    test_acc = accuracy_score(y_test, test_yhat)\n",
    "    #appends the test accuracy score to list. \n",
    "    test_scores.append(test_acc)\n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n",
    "# plot of train and test scores \n",
    "pyplot.plot(values, train_scores, '-o', label='Train')\n",
    "pyplot.plot(values, test_scores, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clincial plus postive regulation of apoptosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added relative path, place path where data is in this line.\n",
    "data = pd.read_csv(\"C:/Users/migue/OneDrive/Desktop/ML Project/Counts/Individual Files/Extracted/Invidual/Transposed_Postive_Regulation_Apoptosis.csv\")\n",
    "print(data)\n",
    "#Need to work on this.\n",
    "x_frame = data.iloc[: , :-1]\n",
    "#x_frame = x_frame.to_numpy()\n",
    "\n",
    "y_frame = data.iloc[:,-1:]\n",
    "\n",
    "\n",
    "print(x_frame)\n",
    "print(y_frame)\n",
    "\n",
    "print(x_frame.shape)\n",
    "\n",
    "print(y_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set varibles for data scaling and  stratified Kfold for the hw examples.\n",
    "# Will need to do boostrapping not stratified kfold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "le = preprocessing.LabelEncoder()\n",
    "oe = OrdinalEncoder()\n",
    "x_frame = oe.fit_transform(x_frame)\n",
    "print(y_frame)\n",
    "y_frame = le.fit_transform(y_frame)\n",
    "print(y_frame)\n",
    "#(categories = ['Age at Index','Age of Diagnosis in Days','Days from Birth','Days to Last Follow UP','Gender','Sample Type','Treament Or Therapy','Treatment Type','Vital Status'])\n",
    "cv_outer = StratifiedKFold(n_splits=6, shuffle=True, random_state=1)\n",
    "cv_inner = StratifiedKFold(n_splits=6, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses CV inner to determine best parameters for xgb using the RandomizedSearchCV parameter optimization. \n",
    "model_xgb = xgb.XGBClassifier(random_state=1,objective='multi:softmax',eval_metric='logloss',use_label_encoder=False,num_class =8)\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('pca', PCA()), \n",
    "    ('model_xgb', model_xgb,)\n",
    "])\n",
    "\n",
    "xgb_param= {\n",
    "    'pca__n_components': [0.60,0.70,0.80,0.90],\n",
    "    'model_xgb__max_depth': [2, 3, 5,7,9],\n",
    "    'model_xgb__n_estimators': [10, 100, 500],\n",
    "    'model_xgb__average':['none','micro','macro','weighted']}\n",
    "xgb_random = RandomizedSearchCV(xgb_pipeline, xgb_param, cv=cv_inner, scoring='accuracy')\n",
    "print(xgb_random)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code below is an example for the hw assignment for how to perform nested k fold on the stratified k fold splits previously.\n",
    "#Sets variables for the following for loop in the code below. \n",
    "import warnings \n",
    "#Silences warnings. \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rf_outer_results = list()\n",
    "rf_best_f1_score=float('-inf')\n",
    "rf_best_parameters={}\n",
    "\n",
    "xgb_outer_results = list()\n",
    "xgb_best_f1_score= float('-inf')\n",
    "xgb_best_parameters={}\n",
    "\n",
    "#for loop that runs 1 times that uses the optimized parameters from above to train the models using a new outer split of the data. \n",
    "iter_num=1\n",
    "for train_ix, test_ix in cv_outer.split(x_frame,y_frame):\n",
    "    print('Iteration',iter_num)\n",
    "    iter_num +=1\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_frame[train_ix, :], y_frame[train_ix], train_size =0.8,test_size =0.2, random_state = 1)\n",
    "    #X_train, X_test = x_frame[train_ix, :], x_frame[test_ix, :]\n",
    "    #y_train, y_test = y_frame[train_ix], y_frame[test_ix]\n",
    "\n",
    "    #XGBoost\n",
    "    result = xgb_random.fit(X_train, y_train)\n",
    "    best_model = result.best_estimator_\n",
    "    yhat = best_model.predict(X_test)\n",
    "    f1score=f1_score(y_test,yhat, average = 'weighted')\n",
    "    if f1score >= xgb_best_f1_score:       \n",
    "        xgb_best_f1_score=f1score\n",
    "        xgb_best_parameters=result.best_params_\n",
    "    xgb_outer_results.append(f1score)\n",
    "    print('XGB inner test: est=%.3f, cfg=%s' % (result.best_score_, result.best_params_))\n",
    "    print()\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "\n",
    "xgb_mean=np.mean(xgb_outer_results)\n",
    "\n",
    "print('XGB outer test: f1-score mean: %.3f (std: %.3f)' % (xgb_mean, np.std(xgb_outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the highest mean between the trained models, it then returns the best performing model based on that. \n",
    "defaulttParm=model_xgb.get_xgb_params()\n",
    "pca=PCA(xgb_best_parameters['pca__n_components'])\n",
    "for k in xgb_best_parameters.keys():\n",
    "    if 'model_xgb' in k:\n",
    "        parm=k.split('__')[1]\n",
    "        defaulttParm[parm]=xgb_best_parameters[k]\n",
    "defaulttParm['use_label_encoder']=True\n",
    "myFinalModel=xgb.XGBClassifier(**defaulttParm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "x_pca=pca.fit_transform(x_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(myFinalModel,x_pca, y_frame,cv=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(myFinalModel,x_frame, y_frame,cv=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines the f-score of the model using a new tenth split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_frame, y_frame, test_size=0.1, random_state=1)\n",
    "myFinalModel.fit(X_train,y_train)\n",
    "yhat=myFinalModel.predict(X_test)\n",
    "f1score=f1_score(yhat,y_test, average ='weighted')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Shap analysis on the predictiors of the data for the class = 0, as it the model balances itself to the final prediction.\n",
    "#Each predictor either increase (red) or decreases(blue) the prediction score. \n",
    "shap.initjs()\n",
    "explainer = shap.KernelExplainer(myFinalModel.predict,X_train)\n",
    "shap_values = explainer.shap_values(X_test[0:,])\n",
    "shap.force_plot(explainer.expected_value, shap_values[2], X_test[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 0.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[0],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code produces a beeswarm plot showing the impact of the top 10 features on the model when its value is 1.\n",
    "#creates the explainer object\n",
    "explainer = shap.TreeExplainer(myFinalModel)\n",
    "#produces values from the test set. \n",
    "shap_values = explainer.shap_values(X_test)\n",
    "#creates the shap object for the plot\n",
    "shap_object = explainer(X_test)\n",
    "#produces the plot\n",
    "shap.summary_plot(shap_values[1],X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the learning curve function from the yellowbrick library to identify if the model could benefit from more training samples. \n",
    "\n",
    "from yellowbrick.model_selection import learning_curve\n",
    "#prints the learning curve plot.\n",
    "print(learning_curve(myFinalModel,x_frame, y_frame,cv=10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "# create dataset with n_samples. \n",
    "X, y = make_classification(n_samples=100000, random_state=1)\n",
    "# split into train test sets 80 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# define lists to collect accuracy scores. \n",
    "train_scores, test_scores = list(), list()\n",
    "# define the tree depths to evaluate\n",
    "values = [i for i in range(1, 21)]\n",
    "#for loop that takes split above and plots train vs test to determine fit.\n",
    "for i in values:\n",
    "    myFinalModel.fit(X_train, y_train)\n",
    "    # evaluate on the train dataset\n",
    "    train_yhat = myFinalModel.predict(X_train)\n",
    "    #determines accuracy score of training data set model.\n",
    "    train_acc = accuracy_score(y_train, train_yhat)\n",
    "    #appends train accuracy score to list. \n",
    "    train_scores.append(train_acc)\n",
    "    # evaluate on the test dataset\n",
    "    test_yhat = myFinalModel.predict(X_test)\n",
    "    #determines accuracy score of test data set model \n",
    "    test_acc = accuracy_score(y_test, test_yhat)\n",
    "    #appends the test accuracy score to list. \n",
    "    test_scores.append(test_acc)\n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n",
    "# plot of train and test scores \n",
    "pyplot.plot(values, train_scores, '-o', label='Train')\n",
    "pyplot.plot(values, test_scores, '-o', label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plots above the models are underfitting and would benefit from more training data. \n",
    "The clical only model is the only one that would not greatly improve from more training data based on its learning curve. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
